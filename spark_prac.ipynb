{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构建一个session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = SparkSession.builder.master(\"lcoal\").appName(\"test\").config(\"spark.some.config.option\", \"some-value\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+---------------------------------------------------+------+---+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|Name                                               |Sex   |Age|SibSp|Parch|Ticket          |Fare   |Cabin|Embarked|\n",
      "+-----------+--------+------+---------------------------------------------------+------+---+-----+-----+----------------+-------+-----+--------+\n",
      "|1          |0       |3     |Braund, Mr. Owen Harris                            |male  |22 |1    |0    |A/5 21171       |7.25   |null |S       |\n",
      "|2          |1       |1     |Cumings, Mrs. John Bradley (Florence Briggs Thayer)|female|38 |1    |0    |PC 17599        |71.2833|C85  |C       |\n",
      "|3          |1       |3     |Heikkinen, Miss. Laina                             |female|26 |0    |0    |STON/O2. 3101282|7.925  |null |S       |\n",
      "|4          |1       |1     |Futrelle, Mrs. Jacques Heath (Lily May Peel)       |female|35 |1    |0    |113803          |53.1   |C123 |S       |\n",
      "|5          |0       |3     |Allen, Mr. William Henry                           |male  |35 |0    |0    |373450          |8.05   |null |S       |\n",
      "+-----------+--------+------+---------------------------------------------------+------+---+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_file = '/home/jovyan/work/titanic/train.csv'\n",
    "df = session.read.csv(train_file,header=True)\n",
    "df.show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pandas 和 spark dataframe 互换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_df = df.toPandas()\n",
    "spark_df = session.createDataFrame(pd_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 行数统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 列数统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 打印列title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PassengerId',\n",
       " 'Survived',\n",
       " 'Pclass',\n",
       " 'Name',\n",
       " 'Sex',\n",
       " 'Age',\n",
       " 'SibSp',\n",
       " 'Parch',\n",
       " 'Ticket',\n",
       " 'Fare',\n",
       " 'Cabin',\n",
       " 'Embarked']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 打印列数据类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PassengerId', 'string'),\n",
       " ('Survived', 'string'),\n",
       " ('Pclass', 'string'),\n",
       " ('Name', 'string'),\n",
       " ('Sex', 'string'),\n",
       " ('Age', 'string'),\n",
       " ('SibSp', 'string'),\n",
       " ('Parch', 'string'),\n",
       " ('Ticket', 'string'),\n",
       " ('Fare', 'string'),\n",
       " ('Cabin', 'string'),\n",
       " ('Embarked', 'string')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 打印数据定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: string (nullable = true)\n",
      " |-- Survived: string (nullable = true)\n",
      " |-- Pclass: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- SibSp: string (nullable = true)\n",
      " |-- Parch: string (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: string (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 改变数据类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PassengerId', 'int'),\n",
       " ('Survived', 'int'),\n",
       " ('Pclass', 'int'),\n",
       " ('Name', 'string'),\n",
       " ('Sex', 'string'),\n",
       " ('Age', 'int'),\n",
       " ('SibSp', 'int'),\n",
       " ('Parch', 'int'),\n",
       " ('Ticket', 'string'),\n",
       " ('Fare', 'double'),\n",
       " ('Cabin', 'string'),\n",
       " ('Embarked', 'string')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.withColumn('PassengerId', df['PassengerId'].cast(IntegerType())).\\\n",
    "    withColumn('Survived', df['Survived'].cast(IntegerType())).\\\n",
    "    withColumn('Pclass', df['Pclass'].cast(IntegerType())).\\\n",
    "    withColumn('Age', df['Age'].cast(IntegerType())).\\\n",
    "    withColumn('SibSp', df['SibSp'].cast(IntegerType())).\\\n",
    "    withColumn('Parch', df['Parch'].cast(IntegerType())).\\\n",
    "    withColumn('Fare', df['Fare'].cast(DoubleType()))\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 列操作（增加列）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-------+\n",
      "|SibSp|Parch|FamSize|\n",
      "+-----+-----+-------+\n",
      "|1    |0    |2      |\n",
      "|1    |0    |2      |\n",
      "|0    |0    |1      |\n",
      "|1    |0    |2      |\n",
      "|0    |0    |1      |\n",
      "+-----+-----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('FamSize', df['SibSp'] + df['Parch'] + 1).select('SibSp', 'Parch', 'FamSize').show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 选取指定列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+---------------------------------------------------+\n",
      "|PassengerId|Survived|Name                                               |\n",
      "+-----------+--------+---------------------------------------------------+\n",
      "|1          |0       |Braund, Mr. Owen Harris                            |\n",
      "|2          |1       |Cumings, Mrs. John Bradley (Florence Briggs Thayer)|\n",
      "|3          |1       |Heikkinen, Miss. Laina                             |\n",
      "|4          |1       |Futrelle, Mrs. Jacques Heath (Lily May Peel)       |\n",
      "|5          |0       |Allen, Mr. William Henry                           |\n",
      "+-----------+--------+---------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('PassengerId','Survived', 'Name').show(5,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 删除指定类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+---------------------------------------------------+------+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|Name                                               |Sex   |SibSp|Parch|Ticket          |Fare   |Cabin|Embarked|\n",
      "+-----------+--------+------+---------------------------------------------------+------+-----+-----+----------------+-------+-----+--------+\n",
      "|1          |0       |3     |Braund, Mr. Owen Harris                            |male  |1    |0    |A/5 21171       |7.25   |null |S       |\n",
      "|2          |1       |1     |Cumings, Mrs. John Bradley (Florence Briggs Thayer)|female|1    |0    |PC 17599        |71.2833|C85  |C       |\n",
      "|3          |1       |3     |Heikkinen, Miss. Laina                             |female|0    |0    |STON/O2. 3101282|7.925  |null |S       |\n",
      "|4          |1       |1     |Futrelle, Mrs. Jacques Heath (Lily May Peel)       |female|1    |0    |113803          |53.1   |C123 |S       |\n",
      "|5          |0       |3     |Allen, Mr. William Henry                           |male  |0    |0    |373450          |8.05   |null |S       |\n",
      "+-----------+--------+------+---------------------------------------------------+------+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.drop('Age').show(5,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 条件过滤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+\n",
      "|Survived|Sex |\n",
      "+--------+----+\n",
      "|0       |male|\n",
      "|0       |male|\n",
      "|0       |male|\n",
      "|0       |male|\n",
      "|0       |male|\n",
      "+--------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = df.filter((df.Survived ==0) &(df.Sex == 'male')).select('Survived','Sex').show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 过滤中的子方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---+\n",
      "|PassengerId|Age|\n",
      "+-----------+---+\n",
      "|1          |22 |\n",
      "|61         |22 |\n",
      "|81         |22 |\n",
      "|89         |23 |\n",
      "|90         |24 |\n",
      "+-----------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df['Age'].between(22, 24)).select('PassengerId', 'Age').show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+---------------------------------------------------+------+---+-----+-----+--------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|Name                                               |Sex   |Age|SibSp|Parch|Ticket  |Fare   |Cabin|Embarked|\n",
      "+-----------+--------+------+---------------------------------------------------+------+---+-----+-----+--------+-------+-----+--------+\n",
      "|2          |1       |1     |Cumings, Mrs. John Bradley (Florence Briggs Thayer)|female|38 |1    |0    |PC 17599|71.2833|C85  |C       |\n",
      "|4          |1       |1     |Futrelle, Mrs. Jacques Heath (Lily May Peel)       |female|35 |1    |0    |113803  |53.1   |C123 |S       |\n",
      "|7          |0       |1     |McCarthy, Mr. Timothy J                            |male  |54 |0    |0    |17463   |51.8625|E46  |S       |\n",
      "|10         |1       |2     |Nasser, Mrs. Nicholas (Adele Achem)                |female|14 |1    |0    |237736  |30.0708|null |C       |\n",
      "|12         |1       |1     |Bonnell, Miss. Elizabeth                           |female|58 |0    |0    |113783  |26.55  |C103 |S       |\n",
      "+-----------+--------+------+---------------------------------------------------+------+---+-----+-----+--------+-------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df['Pclass'].isin([1, 2])).show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UDF函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|NameLen|\n",
      "+-------+\n",
      "|23     |\n",
      "|51     |\n",
      "|22     |\n",
      "|44     |\n",
      "|24     |\n",
      "+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "name_length = udf(lambda s: len(s), IntegerType()) # 默认状态下指定字段为String类型\n",
    "df.select(name_length(df['Name']).alias('NameLen')).show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sort "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "|Age|Fare   |\n",
      "+---+-------+\n",
      "|80 |30.0   |\n",
      "|74 |7.775  |\n",
      "|71 |34.6542|\n",
      "|71 |49.5042|\n",
      "|70 |7.75   |\n",
      "|70 |10.5   |\n",
      "|70 |71.0   |\n",
      "|66 |10.5   |\n",
      "|65 |7.75   |\n",
      "|65 |26.55  |\n",
      "+---+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort(['Age', 'Fare'], ascending=[False, True]).select('Age', 'Fare').show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### drop duplication "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "|Age|Sex   |\n",
      "+---+------+\n",
      "|10 |male  |\n",
      "|24 |male  |\n",
      "|70 |male  |\n",
      "|62 |female|\n",
      "|38 |female|\n",
      "+---+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+---+------+\n",
      "|Age|Sex   |\n",
      "+---+------+\n",
      "|10 |male  |\n",
      "|24 |male  |\n",
      "|70 |male  |\n",
      "|62 |female|\n",
      "|38 |female|\n",
      "+---+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+---+------+\n",
      "|Age|Sex   |\n",
      "+---+------+\n",
      "|10 |male  |\n",
      "|24 |male  |\n",
      "|70 |male  |\n",
      "|62 |female|\n",
      "|38 |female|\n",
      "+---+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(['Age','Sex']).distinct().show(5,False)\n",
    "df.select(['Age','Sex']).dropDuplicates().show(5,False)\n",
    "df.select(['Age','Sex']).drop_duplicates().show(5,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### isnull\n",
    "null : is nothing\n",
    "nan : is not a number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|PassengerId|Cabin|\n",
      "+-----------+-----+\n",
      "|1          |null |\n",
      "|3          |null |\n",
      "|5          |null |\n",
      "|6          |null |\n",
      "|8          |null |\n",
      "+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(isnull('Cabin')).select('PassengerId', 'Cabin').show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### remove null row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|PassengerId|Cabin|\n",
      "+-----------+-----+\n",
      "|2          |C85  |\n",
      "|4          |C123 |\n",
      "|7          |E46  |\n",
      "|11         |G6   |\n",
      "|12         |C103 |\n",
      "+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.dropna(subset=['Cabin']).select('PassengerId', 'Cabin').show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 填充缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "|Age|Cabin  |\n",
      "+---+-------+\n",
      "|22 |NaCabin|\n",
      "|38 |C85    |\n",
      "|26 |NaCabin|\n",
      "|35 |C123   |\n",
      "|35 |NaCabin|\n",
      "|-1 |NaCabin|\n",
      "|54 |E46    |\n",
      "|2  |NaCabin|\n",
      "|27 |NaCabin|\n",
      "|14 |NaCabin|\n",
      "+---+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.fillna(value={'Cabin':'NaCabin', 'Age':-1}).select('Age', 'Cabin').show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+-------------------------------------------------------+------+---+-----+-----+----------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|Name                                                   |Sex   |Age|SibSp|Parch|Ticket    |Fare   |Cabin|Embarked|\n",
      "+-----------+--------+------+-------------------------------------------------------+------+---+-----+-----+----------+-------+-----+--------+\n",
      "|85         |1       |2     |Ilett, Miss. Bertha                                    |female|17 |0    |0    |SO/C 14885|10.5   |null |S       |\n",
      "|86         |1       |3     |Backstrom, Mrs. Karl Alfred (Maria Mathilda Gustafsson)|female|33 |3    |0    |3101278   |15.85  |null |S       |\n",
      "|126        |1       |3     |Nicola-Yarred, Master. Elias                           |male  |12 |1    |0    |2651      |11.2417|null |C       |\n",
      "|130        |0       |3     |Ekstrom, Mr. Johan                                     |male  |45 |0    |0    |347061    |6.975  |null |S       |\n",
      "|135        |0       |2     |Sobey, Mr. Samuel James Hayden                         |male  |25 |0    |0    |C.A. 29178|13.0   |null |S       |\n",
      "+-----------+--------+------+-------------------------------------------------------+------+---+-----+-----+----------+-------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sample(withReplacement=False, fraction=0.05, seed=2).show(5,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 分层抽样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "577\n",
      "314\n",
      "60\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "test = df.sampleBy(col='Sex', fractions={'male':0.1, 'female':0.2}, seed=2)\n",
    "print(df.filter(test.Sex == 'male').count())\n",
    "print(df.filter(test.Sex == 'female').count())\n",
    "print(test.filter(test.Sex == 'male').count())\n",
    "print(test.filter(test.Sex == 'female').count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 分组 groupby + agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------------+-----------------+---------------------+-------+------------------+\n",
      "|Pclass|Survived|cnt_embarked|cnt_dist_embarked|app_cnt_dist_embarked|max_age|avg_age           |\n",
      "+------+--------+------------+-----------------+---------------------+-------+------------------+\n",
      "|1     |0       |80          |3                |3                    |71     |43.6875           |\n",
      "|3     |1       |119         |3                |3                    |63     |20.623529411764707|\n",
      "|1     |1       |134         |3                |3                    |80     |35.36065573770492 |\n",
      "|2     |1       |87          |3                |3                    |62     |25.867469879518072|\n",
      "|2     |0       |97          |3                |3                    |70     |33.53333333333333 |\n",
      "|3     |0       |372         |3                |3                    |74     |26.52962962962963 |\n",
      "+------+--------+------------+-----------------+---------------------+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# count/count distinct\n",
    "# max/min/sum\n",
    "# mean/avg\n",
    "# alias\n",
    "df.\\\n",
    "    groupBy(['Pclass', 'Survived']).\\\n",
    "    agg(count('Embarked').alias('cnt_embarked'), \\\n",
    "        countDistinct('Embarked').alias('cnt_dist_embarked'), \\\n",
    "        # 巨大なデータを集計する際に、approximateを使った方がいい(精度とパフォマンスのトレードオフ)\n",
    "        approx_count_distinct('Embarked').alias('app_cnt_dist_embarked'), \\\n",
    "        max('Age').alias('max_age'), \\\n",
    "        avg('Age').alias('avg_age'), \\\n",
    "        # mean('Age').alias('avg_age'), \\\n",
    "       ).\\\n",
    "    show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join key名一样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+------+------+\n",
      "|PassengerId|Fare   |Sex   |Sex_JP|\n",
      "+-----------+-------+------+------+\n",
      "|1          |7.25   |male  |男性    |\n",
      "|2          |71.2833|female|女性    |\n",
      "|3          |7.925  |female|女性    |\n",
      "|4          |53.1   |female|女性    |\n",
      "|5          |8.05   |male  |男性    |\n",
      "|6          |8.4583 |male  |男性    |\n",
      "|7          |51.8625|male  |男性    |\n",
      "|8          |21.075 |male  |男性    |\n",
      "|9          |11.1333|female|女性    |\n",
      "|10         |30.0708|female|女性    |\n",
      "+-----------+-------+------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 新建df\n",
    "new_df = df.replace(['male', 'female'], ['男性', '女性'], 'Sex').selectExpr('PassengerId', 'Sex AS Sex_JP', 'Fare')\n",
    "# join\n",
    "df.selectExpr('PassengerId', 'Sex', 'Fare').join(new_df, ['PassengerId', 'Fare']).show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### join key名不一样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------+--------+-----------+------+--------+\n",
      "|Old_PassengerId|Sex   |Old_Fare|PassengerId|Sex_JP|Fare    |\n",
      "+---------------+------+--------+-----------+------+--------+\n",
      "|121            |male  |73.5    |121        |男性    |73.5    |\n",
      "|644            |male  |56.4958 |644        |男性    |56.4958 |\n",
      "|655            |female|6.75    |655        |女性    |6.75    |\n",
      "|690            |female|211.3375|690        |女性    |211.3375|\n",
      "|18             |male  |13.0    |18         |男性    |13.0    |\n",
      "|117            |male  |7.75    |117        |男性    |7.75    |\n",
      "|225            |male  |90.0    |225        |男性    |90.0    |\n",
      "|347            |female|13.0    |347        |女性    |13.0    |\n",
      "|568            |female|21.075  |568        |女性    |21.075  |\n",
      "|716            |male  |7.65    |716        |男性    |7.65    |\n",
      "+---------------+------+--------+-----------+------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "old_df = df.selectExpr('PassengerId AS Old_PassengerId', 'Sex', 'Fare AS Old_Fare')\n",
    "join_cond = [old_df.Old_PassengerId == new_df.PassengerId, old_df.Old_Fare == new_df.Fare]\n",
    "old_df.\\\n",
    "    join(new_df, on=join_cond, how='outer').show(10, False)\n",
    "# how: default ‘inner’. One of inner, outer, left_outer, right_outer, leftsemi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------+-----+\n",
      "|Pclass|Survived|female|male |\n",
      "+------+--------+------+-----+\n",
      "|1     |0       |110.6 |62.89|\n",
      "|3     |1       |12.46 |15.58|\n",
      "|1     |1       |105.98|74.64|\n",
      "|2     |1       |22.29 |21.1 |\n",
      "|2     |0       |18.25 |19.49|\n",
      "|3     |0       |19.77 |12.2 |\n",
      "+------+--------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Pclass', 'Survived').\\\n",
    "    pivot('Sex').\\\n",
    "    agg(round(avg('Fare'),2)).\\\n",
    "    show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### broadcast 快速join\n",
    "boadcast的目的是数据copy多个副本然后发送给cluster的各个节点进行分布式处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+------+------+\n",
      "|PassengerId|Fare   |Sex   |Sex_JP|\n",
      "+-----------+-------+------+------+\n",
      "|1          |7.25   |male  |男性    |\n",
      "|2          |71.2833|female|女性    |\n",
      "|3          |7.925  |female|女性    |\n",
      "|4          |53.1   |female|女性    |\n",
      "|5          |8.05   |male  |男性    |\n",
      "|6          |8.4583 |male  |男性    |\n",
      "|7          |51.8625|male  |男性    |\n",
      "|8          |21.075 |male  |男性    |\n",
      "|9          |11.1333|female|女性    |\n",
      "|10         |30.0708|female|女性    |\n",
      "+-----------+-------+------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.selectExpr('PassengerId', 'Sex', 'Fare').join(broadcast(new_df), ['PassengerId', 'Fare']).show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 缓存dataframe cache用法\n",
    "persist: http://spark.apache.org/docs/latest/rdd-programming-guide.html#rdd-persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------+---------------+\n",
      "|Pclass|Survived|cnt_ID|app_cnt_dist_ID|\n",
      "+------+--------+------+---------------+\n",
      "|1     |0       |80    |82             |\n",
      "|3     |1       |119   |120            |\n",
      "+------+--------+------+---------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[Pclass: int, Survived: int, cnt_ID: bigint, app_cnt_dist_ID: bigint]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 确认是否被cache过\n",
    "df.is_cached\n",
    "\n",
    "# cache\n",
    "df.cache()\n",
    "\n",
    "# 取消cache\n",
    "df.unpersist()\n",
    "\n",
    "# 例子\n",
    "result_df = df.\\\n",
    "    groupBy(['Pclass', 'Survived']).\\\n",
    "    agg(count('PassengerId').alias('cnt_ID')\\\n",
    "    , approx_count_distinct('PassengerId').alias('app_cnt_dist_ID')\\\n",
    "    ).\\\n",
    "    cache()  \n",
    "\n",
    "# 在逻辑被第一次执行的时候需要花费一定时间\n",
    "result_df.show(2, False)\n",
    " \n",
    "# 由于之前的df已经被缓存，所以之后的逻辑会很快被完成\n",
    "result_df.count()\n",
    " \n",
    "# 在使用结束之后，记得释放内存\n",
    "result_df.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看df被分成几个partition\n",
    "print(df.rdd.getNumPartitions())\n",
    "# 重新设定partition\n",
    "df_repartitioned = df.repartition(10)\n",
    "print(df_repartitioned.rdd.getNumPartitions())\n",
    "df_repartitioned.coalesce(1).rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出成csv\n",
    "df.write.mode('overwrite').csv('df_csv', header=True, sep=';')\n",
    "# 输出一个csv\n",
    "df.coalesce(10).write.mode('overwrite').csv('df_csv', header=True, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 合并结果文件夹中的多个文件为一个文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CombineSparkOutput(csv_path, header=None, sep=',', new_csv_name=None, remove_original_file=False):\n",
    "    \"\"\"Combine Spark output files into 1 csv file and rename it.\n",
    "    Parameters\n",
    "    ----------\n",
    "    csv_path : string\n",
    "        path of csv folder.\n",
    "    header : None or int\n",
    "        same as pandas.\n",
    "    sep : string\n",
    "        same as pandas.\n",
    "    new_csv_name : string\n",
    "        file name of new csv file.\n",
    "    remove_original_file : boolean, default False\n",
    "        if remove original csv folder or not\n",
    "    Returns\n",
    "    -------\n",
    "     \n",
    "    \"\"\"\n",
    "     \n",
    "    # 全てのcsvファイル\n",
    "    all_csv_files = [file for file in os.listdir(path=csv_path) if len(re.findall('csv$', file)) > 0]\n",
    "    # 空のdataframeを作成\n",
    "    total_df = pd.read_csv(os.path.join(csv_path, all_csv_files[0]), \\\n",
    "                           header=header, sep=sep, nrows=0)\n",
    "    # Loopでdataframeを追加\n",
    "    for csv_file in all_csv_files:\n",
    "        # 空のcsvファイルを飛ばす\n",
    "        if os.path.getsize(os.path.join(csv_path, csv_file)) > 0:\n",
    "            df = pd.read_csv(os.path.join(csv_path, csv_file), \\\n",
    "                             header=header, sep=sep)\n",
    "            total_df = total_df.append(df)\n",
    "        else:\n",
    "            continue\n",
    "     \n",
    "    # csvファイルを出力\n",
    "    total_df.to_csv(new_csv_name, header=header, sep=sep)\n",
    "    # 過去のファイルを削除\n",
    "    if remove_original_file:\n",
    "        shutil.rmtree(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import pandas as pd\n",
    "# pyspark输出\n",
    "df.write.mode('overwrite').csv('df_csv', header=None, sep=';')\n",
    "# pandas\n",
    "CombineSparkOutput('df_csv', header=None, sep=';', new_csv_name='df.csv', remove_original_file=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+-------+\n",
      "|col_name   |data_type|comment|\n",
      "+-----------+---------+-------+\n",
      "|PassengerId|int      |null   |\n",
      "|Survived   |int      |null   |\n",
      "|Pclass     |int      |null   |\n",
      "|Name       |string   |null   |\n",
      "|Sex        |string   |null   |\n",
      "|Age        |int      |null   |\n",
      "|SibSp      |int      |null   |\n",
      "|Parch      |int      |null   |\n",
      "|Ticket     |string   |null   |\n",
      "|Fare       |double   |null   |\n",
      "+-----------+---------+-------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+--------+---------+-----------+\n",
      "|database|tableName|isTemporary|\n",
      "+--------+---------+-----------+\n",
      "|        |df_view  |true       |\n",
      "+--------+---------+-----------+\n",
      "\n",
      "+--------+---------+-----------+\n",
      "|database|tableName|isTemporary|\n",
      "+--------+---------+-----------+\n",
      "+--------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 新建View\n",
    "df.createOrReplaceTempView(\"df_view\")\n",
    "\n",
    "# 查看view的内容\n",
    "session.sql('DESC df_view').show(10, False)\n",
    "\n",
    "# 现存的table/view\n",
    "session.sql('SHOW TABLES').show(10, False)\n",
    "\n",
    "# 删除View\n",
    "session.catalog.dropTempView('df_view')\n",
    "# 也可以用query\n",
    "# session.sql('DROP VIEW IF EXISTS df_view')\n",
    "\n",
    "# 查看tables\n",
    "session.sql('SHOW TABLES').show(10, False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  database导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新建database\n",
    "# 需要指定存放data的s3目录\n",
    "session.sql(\"CREATE DATABASE IF NOT EXISTS titanic \\\n",
    "COMMENT 'test db' \\\n",
    "LOCATION 'S3/path/to' \")\n",
    "\n",
    "# 向table中输出数据\n",
    "df.write.saveAsTable('titanic.test')\n",
    "\n",
    "# 用parquet速度更快\n",
    "df_graph\\\n",
    "    .write\\\n",
    "    .format('parquet')\\\n",
    "    .partitionBy('')\\\n",
    "    .mode('overwrite')\\\n",
    "    .saveAsTable( 'titanic.test', Path='S3/path/to' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 版本确认"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### parquet 文件读写"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 写\n",
    "df.write.mode('overwrite').parquet('df_parquet')\n",
    "# 读\n",
    "df2 = spark.read.parquet('df_parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 两个dataframe比较差值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.subtract(df2).show(10, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
